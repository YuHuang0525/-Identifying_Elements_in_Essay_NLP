{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03a01f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e798585",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13b6b945",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144288</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618153e+12</td>\n",
       "      <td>2234.0</td>\n",
       "      <td>3203.0</td>\n",
       "      <td>if I'm not sure what college I want to attend...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>386 387 388 389 390 391 392 393 394 395 396 39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144289</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618153e+12</td>\n",
       "      <td>3221.0</td>\n",
       "      <td>4509.0</td>\n",
       "      <td>seeking multiple opinions before making a har...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 3</td>\n",
       "      <td>576 577 578 579 580 581 582 583 584 585 586 58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144290</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618025e+12</td>\n",
       "      <td>4510.0</td>\n",
       "      <td>4570.0</td>\n",
       "      <td>it is better to seek multiple opinions instead...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>828 829 830 831 832 833 834 835 836 837 838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144291</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618025e+12</td>\n",
       "      <td>4570.0</td>\n",
       "      <td>4922.0</td>\n",
       "      <td>The impact of asking people to help you make a...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 4</td>\n",
       "      <td>839 840 841 842 843 844 845 846 847 848 849 85...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144292</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618025e+12</td>\n",
       "      <td>4935.0</td>\n",
       "      <td>5825.0</td>\n",
       "      <td>there are many other reasons one might want to...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>905 906 907 908 909 910 911 912 913 914 915 91...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144293 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  discourse_id  discourse_start  discourse_end  \\\n",
       "0       423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "1       423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "2       423A1CA112E2  1.622628e+12            313.0          401.0   \n",
       "3       423A1CA112E2  1.622628e+12            402.0          758.0   \n",
       "4       423A1CA112E2  1.622628e+12            759.0          886.0   \n",
       "...              ...           ...              ...            ...   \n",
       "144288  4C471936CD75  1.618153e+12           2234.0         3203.0   \n",
       "144289  4C471936CD75  1.618153e+12           3221.0         4509.0   \n",
       "144290  4C471936CD75  1.618025e+12           4510.0         4570.0   \n",
       "144291  4C471936CD75  1.618025e+12           4570.0         4922.0   \n",
       "144292  4C471936CD75  1.618025e+12           4935.0         5825.0   \n",
       "\n",
       "                                           discourse_text  \\\n",
       "0       Modern humans today are always on their phone....   \n",
       "1       They are some really bad consequences when stu...   \n",
       "2       Some certain areas in the United States ban ph...   \n",
       "3       When people have phones, they know about certa...   \n",
       "4       Driving is one of the way how to get around. P...   \n",
       "...                                                   ...   \n",
       "144288   if I'm not sure what college I want to attend...   \n",
       "144289   seeking multiple opinions before making a har...   \n",
       "144290  it is better to seek multiple opinions instead...   \n",
       "144291  The impact of asking people to help you make a...   \n",
       "144292  there are many other reasons one might want to...   \n",
       "\n",
       "              discourse_type      discourse_type_num  \\\n",
       "0                       Lead                  Lead 1   \n",
       "1                   Position              Position 1   \n",
       "2                   Evidence              Evidence 1   \n",
       "3                   Evidence              Evidence 2   \n",
       "4                      Claim                 Claim 1   \n",
       "...                      ...                     ...   \n",
       "144288              Evidence              Evidence 2   \n",
       "144289              Evidence              Evidence 3   \n",
       "144290              Position              Position 1   \n",
       "144291              Evidence              Evidence 4   \n",
       "144292  Concluding Statement  Concluding Statement 1   \n",
       "\n",
       "                                         predictionstring  \n",
       "0       1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1            45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2         60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3       76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4       139 140 141 142 143 144 145 146 147 148 149 15...  \n",
       "...                                                   ...  \n",
       "144288  386 387 388 389 390 391 392 393 394 395 396 39...  \n",
       "144289  576 577 578 579 580 581 582 583 584 585 586 58...  \n",
       "144290        828 829 830 831 832 833 834 835 836 837 838  \n",
       "144291  839 840 841 842 843 844 845 846 847 848 849 85...  \n",
       "144292  905 906 907 908 909 910 911 912 913 914 915 91...  \n",
       "\n",
       "[144293 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c68d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path('train')\n",
    "\n",
    "def get_raw_text(ids):\n",
    "    with open(path/f'{ids}.txt', 'r') as file: data = file.read()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "338ee187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>[0.0, 170.0, 358.0, 438.0, 627.0, 722.0, 836.0...</td>\n",
       "      <td>[170.0, 357.0, 438.0, 626.0, 722.0, 836.0, 101...</td>\n",
       "      <td>[Position, Evidence, Evidence, Claim, Counterc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00066EA9880D</td>\n",
       "      <td>[0.0, 456.0, 638.0, 738.0, 1399.0, 1488.0, 231...</td>\n",
       "      <td>[455.0, 592.0, 738.0, 1398.0, 1487.0, 2219.0, ...</td>\n",
       "      <td>[Lead, Position, Claim, Evidence, Claim, Evide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000E6DE9E817</td>\n",
       "      <td>[17.0, 64.0, 158.0, 310.0, 438.0, 551.0, 776.0...</td>\n",
       "      <td>[56.0, 157.0, 309.0, 422.0, 551.0, 775.0, 961....</td>\n",
       "      <td>[Position, Counterclaim, Rebuttal, Evidence, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001552828BD0</td>\n",
       "      <td>[0.0, 161.0, 872.0, 958.0, 1191.0, 1542.0, 161...</td>\n",
       "      <td>[160.0, 872.0, 957.0, 1190.0, 1541.0, 1612.0, ...</td>\n",
       "      <td>[Lead, Evidence, Claim, Claim, Evidence, Claim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>[0.0, 58.0, 94.0, 206.0, 236.0, 272.0, 542.0, ...</td>\n",
       "      <td>[57.0, 91.0, 150.0, 235.0, 271.0, 542.0, 650.0...</td>\n",
       "      <td>[Position, Claim, Claim, Claim, Claim, Evidenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15589</th>\n",
       "      <td>FFF1442D6698</td>\n",
       "      <td>[0.0, 640.0, 710.0, 778.0, 841.0, 1291.0, 2104...</td>\n",
       "      <td>[639.0, 710.0, 778.0, 826.0, 1222.0, 2103.0, 2...</td>\n",
       "      <td>[Lead, Position, Claim, Claim, Evidence, Evide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15590</th>\n",
       "      <td>FFF1ED4F8544</td>\n",
       "      <td>[0.0, 351.0, 458.0, 513.0, 555.0, 606.0, 767.0...</td>\n",
       "      <td>[351.0, 457.0, 512.0, 555.0, 605.0, 767.0, 183...</td>\n",
       "      <td>[Lead, Position, Claim, Claim, Claim, Claim, E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15591</th>\n",
       "      <td>FFF868E06176</td>\n",
       "      <td>[0.0, 226.0, 417.0, 502.0, 996.0, 1089.0, 1364...</td>\n",
       "      <td>[225.0, 324.0, 501.0, 914.0, 1088.0, 1363.0, 1...</td>\n",
       "      <td>[Lead, Position, Claim, Evidence, Claim, Evide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15592</th>\n",
       "      <td>FFFD0AF13501</td>\n",
       "      <td>[237.0, 281.0, 348.0, 431.0, 517.0, 584.0, 959...</td>\n",
       "      <td>[280.0, 347.0, 431.0, 516.0, 583.0, 943.0, 105...</td>\n",
       "      <td>[Claim, Claim, Evidence, Claim, Claim, Evidenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15593</th>\n",
       "      <td>FFFF80B8CC2F</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[990.0]</td>\n",
       "      <td>[Evidence]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15594 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                    discourse_start  \\\n",
       "0      0000D23A521A  [0.0, 170.0, 358.0, 438.0, 627.0, 722.0, 836.0...   \n",
       "1      00066EA9880D  [0.0, 456.0, 638.0, 738.0, 1399.0, 1488.0, 231...   \n",
       "2      000E6DE9E817  [17.0, 64.0, 158.0, 310.0, 438.0, 551.0, 776.0...   \n",
       "3      001552828BD0  [0.0, 161.0, 872.0, 958.0, 1191.0, 1542.0, 161...   \n",
       "4      0016926B079C  [0.0, 58.0, 94.0, 206.0, 236.0, 272.0, 542.0, ...   \n",
       "...             ...                                                ...   \n",
       "15589  FFF1442D6698  [0.0, 640.0, 710.0, 778.0, 841.0, 1291.0, 2104...   \n",
       "15590  FFF1ED4F8544  [0.0, 351.0, 458.0, 513.0, 555.0, 606.0, 767.0...   \n",
       "15591  FFF868E06176  [0.0, 226.0, 417.0, 502.0, 996.0, 1089.0, 1364...   \n",
       "15592  FFFD0AF13501  [237.0, 281.0, 348.0, 431.0, 517.0, 584.0, 959...   \n",
       "15593  FFFF80B8CC2F                                              [0.0]   \n",
       "\n",
       "                                           discourse_end  \\\n",
       "0      [170.0, 357.0, 438.0, 626.0, 722.0, 836.0, 101...   \n",
       "1      [455.0, 592.0, 738.0, 1398.0, 1487.0, 2219.0, ...   \n",
       "2      [56.0, 157.0, 309.0, 422.0, 551.0, 775.0, 961....   \n",
       "3      [160.0, 872.0, 957.0, 1190.0, 1541.0, 1612.0, ...   \n",
       "4      [57.0, 91.0, 150.0, 235.0, 271.0, 542.0, 650.0...   \n",
       "...                                                  ...   \n",
       "15589  [639.0, 710.0, 778.0, 826.0, 1222.0, 2103.0, 2...   \n",
       "15590  [351.0, 457.0, 512.0, 555.0, 605.0, 767.0, 183...   \n",
       "15591  [225.0, 324.0, 501.0, 914.0, 1088.0, 1363.0, 1...   \n",
       "15592  [280.0, 347.0, 431.0, 516.0, 583.0, 943.0, 105...   \n",
       "15593                                            [990.0]   \n",
       "\n",
       "                                          discourse_type  \n",
       "0      [Position, Evidence, Evidence, Claim, Counterc...  \n",
       "1      [Lead, Position, Claim, Evidence, Claim, Evide...  \n",
       "2      [Position, Counterclaim, Rebuttal, Evidence, C...  \n",
       "3      [Lead, Evidence, Claim, Claim, Evidence, Claim...  \n",
       "4      [Position, Claim, Claim, Claim, Claim, Evidenc...  \n",
       "...                                                  ...  \n",
       "15589  [Lead, Position, Claim, Claim, Evidence, Evide...  \n",
       "15590  [Lead, Position, Claim, Claim, Claim, Claim, E...  \n",
       "15591  [Lead, Position, Claim, Evidence, Claim, Evide...  \n",
       "15592  [Claim, Claim, Evidence, Claim, Claim, Evidenc...  \n",
       "15593                                         [Evidence]  \n",
       "\n",
       "[15594 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1 = pd.DataFrame(dataset.groupby('id')['discourse_start'].apply(list))\n",
    "temp1 = temp1.reset_index()\n",
    "temp2 = pd.DataFrame(dataset.groupby('id')['discourse_end'].apply(list))\n",
    "temp2 = temp2.reset_index()\n",
    "temp3 = pd.DataFrame(dataset.groupby('id')['discourse_type'].apply(list))\n",
    "temp3 = temp3.reset_index()\n",
    "temp1 = temp1.merge(temp2)\n",
    "temp1 = temp1.merge(temp3)\n",
    "temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e98d5a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1['raw_text'] = temp1['id'].apply(get_raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14a51efc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbb5d546",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds = Dataset.from_pandas(temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf4ac55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ds.train_test_split(test_size=0.1, shuffle=True, seed=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f981aebc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained('allenai/longformer-base-4096', \n",
    "                                          add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12cf06d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'o': 0,\n",
    "             'B-Lead': 1,\n",
    "             'I-Lead': 2,\n",
    "             'B-Position': 3,\n",
    "             'I-Position': 4,\n",
    "             'B-Evidence': 5,\n",
    "             'I-Evidence': 6,\n",
    "             'B-Claim': 7,\n",
    "             'I-Claim': 8,\n",
    "             'B-Concluding Statement': 9,\n",
    "             'I-Concluding Statement': 10,\n",
    "             'B-Counterclaim': 11,\n",
    "             'I-Counterclaim': 12, \n",
    "             'B-Rebuttal': 13,\n",
    "             'I-Rebuttal':14,\n",
    "             'special':15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ade1065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_assign_labels(x):\n",
    "    try:\n",
    "        o = tokenizer(x['raw_text'], truncation=True, padding=True,\n",
    "                      max_length=1024, return_offsets_mapping=True)\n",
    "\n",
    "        offset = o['offset_mapping']\n",
    "\n",
    "        labels = [0] * len(offset)\n",
    "        i = 0\n",
    "        while i < len(offset):\n",
    "            if offset[i][0] == offset[i][1]:\n",
    "                    labels[i] = label_dict['special']\n",
    "                    i += 1\n",
    "                    continue\n",
    "            elif offset[i][0] in x['discourse_start']:\n",
    "                temp_idx = x['discourse_start'].index(offset[i][0])\n",
    "                temp_label = 'B-' + x['discourse_type'][temp_idx]\n",
    "                temp_idx_end = x['discourse_end'][temp_idx]\n",
    "                labels[i] = label_dict[temp_label]\n",
    "\n",
    "                temp_label = 'I-' + x['discourse_type'][temp_idx]\n",
    "                j = i+1\n",
    "                while j != len(offset):\n",
    "                    if offset[j][0] < temp_idx_end:\n",
    "                        labels[j] = label_dict[temp_label]\n",
    "                        j += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        break\n",
    "                i = j\n",
    "                continue\n",
    "            else:\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "        o['labels'] = [labels]\n",
    "        # 下面这里是和vesion 1.2 不一样的地方\n",
    "        o['input_ids'] = [o['input_ids']]\n",
    "        o['attention_mask'] = [o['attention_mask']]\n",
    "        o['offset_mapping'] = [o['offset_mapping']]\n",
    "        return o        \n",
    "    except:\n",
    "        print(x['id'])\n",
    "        print(j)\n",
    "        print(temp_idx_end)\n",
    "        print(temp_label)\n",
    "        print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e2fd51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 0\n",
    "for x in datasets['train']:\n",
    "    if x['id'] == '7D95539DC1AE':\n",
    "        temp = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5a755dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = tokenizer(temp['raw_text'],truncation=True, padding=True,\n",
    "                      max_length=1024, return_offsets_mapping=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "393d026f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a633584f304469b50b04e30caa11e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef26959ec1074d88b9b0e64caa0240c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(tokenize_assign_labels, batched=True,\n",
    "                                  batch_size=20000,\n",
    "                                  remove_columns=datasets[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52b96833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a41e85fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "366b1ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForTokenClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForTokenClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained('allenai/longformer-base-4096', num_labels=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89aad2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./feedback1.2',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    report_to='wandb',\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    gradient_accumulation_steps=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6f6327b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f39c4f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07c3d948",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'wandb' has no attribute 'login'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m0/r4gc8d8x2dz_h2ymv3jgxbv80000gn/T/ipykernel_49562/2366315092.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'wandb' has no attribute 'login'"
     ]
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f861bede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/yuh014/feedback1.3/runs/1a3u8x8n\" target=\"_blank\">grateful-leaf-1</a></strong> to <a href=\"https://wandb.ai/yuh014/feedback1.3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/yuh014/feedback1.3/runs/1a3u8x8n?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fe21c162dc0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"feedback1.3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5eca3296",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5e0639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `LongformerForTokenClassification.forward` and have been ignored: offset_mapping.\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Input ids are automatically padded from 14034 to 14336 to be a multiple of `config.attention_window`: 512\n",
      "Exception in thread ChkStopThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/huangyu/opt/anaconda3/envs/feedback/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "Exception in thread NetStatThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/huangyu/opt/anaconda3/envs/feedback/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/huangyu/opt/anaconda3/envs/feedback/lib/python3.8/threading.py\", line 870, in run\n",
      "    self.run()\n",
      "  File \"/Users/huangyu/opt/anaconda3/envs/feedback/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/huangyu/opt/anaconda3/envs/feedback/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 170, in check_status\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/huangyu/opt/anaconda3/envs/feedback/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 152, in check_network_status\n",
      "    status_response = self._interface.communicate_stop_status()    status_response = self._interface.communicate_network_status()\n",
      "\n",
      "  File \"/Users/huangyu/opt/anaconda3/envs/feedback/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\", line 114, in communicate_stop_status\n",
      "  File \"/Users/huangyu/opt/anaconda3/envs/feedback/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\", line 125, in communicate_network_status\n",
      "    resp = self._communicate_stop_status(status)\n",
      "  File \"/Users/huangyu/opt/anaconda3/envs/feedback/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py\", line 378, in _communicate_stop_status\n",
      "    resp = self._communicate_network_status(status)\n",
      "  File \"/Users/huangyu/opt/anaconda3/envs/feedback/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py\", line 388, in _communicate_network_status\n",
      "        resp = self._communicate(req, local=True)resp = self._communicate(req, local=True)\n",
      "\n",
      "  File \"/Users/huangyu/opt/anaconda3/envs/feedback/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py\", line 213, in _communicate\n",
      "  File \"/Users/huangyu/opt/anaconda3/envs/feedback/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py\", line 213, in _communicate\n",
      "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
      "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
      "  File \"/Users/huangyu/opt/anaconda3/envs/feedback/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py\", line 218, in _communicate_async\n",
      "  File \"/Users/huangyu/opt/anaconda3/envs/feedback/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py\", line 218, in _communicate_async\n",
      "    raise Exception(\"The wandb backend process has shutdown\")\n",
      "    raise Exception(\"The wandb backend process has shutdown\")Exception\n",
      "Exception: : The wandb backend process has shutdownThe wandb backend process has shutdown\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7606af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a015faa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2999815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3074a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d26f519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea8189e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7be3baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efdc48e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
